# üé¨ GUION DE DEMOSTRACI√ìN - TAREA 2
## Sistema As√≠ncrono con Apache Kafka y Apache Flink

---

## üìã TABLA DE CONTENIDOS
1. [Preparaci√≥n Inicial](#1-preparaci√≥n-inicial)
2. [Demostraci√≥n de Arquitectura](#2-demostraci√≥n-de-arquitectura)
3. [Pipeline As√≠ncrono con Kafka](#3-pipeline-as√≠ncrono-con-kafka)
4. [Gesti√≥n de Fallos y Reintentos](#4-gesti√≥n-de-fallos-y-reintentos)
5. [Procesamiento de Flujos con Flink](#5-procesamiento-de-flujos-con-flink)
6. [An√°lisis de M√©tricas](#6-an√°lisis-de-m√©tricas)
7. [Preguntas y Respuestas](#7-preguntas-y-respuestas)

---

## 1. PREPARACI√ìN INICIAL

### 1.1 Verificar Prerequisitos

```powershell
# Verificar Docker
Write-Host "`n=== VERIFICANDO PREREQUISITOS ===" -ForegroundColor Cyan
docker --version
docker-compose --version

# Verificar Ollama (LLM local)
ollama list
```

**Narraci√≥n**: 
> "Comenzamos verificando que tenemos Docker, Docker Compose y Ollama instalados. Ollama nos permite ejecutar el modelo LLM de forma local, eliminando restricciones de rate limiting."

### 1.2 Posicionarse en el Directorio del Proyecto

```powershell
cd "d:\U\Sistemas Distribuidos\Docker\yahoo_llm_project"
Get-ChildItem -Name
```

**Narraci√≥n**:
> "Navegamos al directorio del proyecto donde encontramos todos los componentes: servicios de consumidores, configuraciones de Kafka, el job de Flink compilado, y la documentaci√≥n t√©cnica."

### 1.3 Mostrar la Documentaci√≥n Clave

```powershell
# Mostrar documentos principales
Write-Host "`n=== DOCUMENTACI√ìN DEL PROYECTO ===" -ForegroundColor Yellow
Get-ChildItem -Filter "*.md" | Select-Object Name, Length, LastWriteTime
```

**Narraci√≥n**:
> "Tenemos documentaci√≥n exhaustiva que incluye:
> - README_TAREA2_FLINK.md: Arquitectura t√©cnica completa
> - CUMPLIMIENTO_TAREA2.md: Verificaci√≥n de todos los requerimientos
> - ANALISIS_SCORES.md: Justificaci√≥n del umbral de calidad
> - DASHBOARD_VISUALIZACION.md: Documentaci√≥n del sistema de m√©tricas"

---

## 2. DEMOSTRACI√ìN DE ARQUITECTURA

### 2.1 Mostrar el Docker Compose

```powershell
Write-Host "`n=== ARQUITECTURA DEL SISTEMA ===" -ForegroundColor Cyan
notepad docker-compose-tarea2.yml
```

**Narraci√≥n**:
> "Nuestro docker-compose orquesta 15 contenedores:
> 
> **Infraestructura Base (Tarea 1)**:
> - PostgreSQL: Base de datos principal
> - Redis: Sistema de cach√© con pol√≠tica LRU
> 
> **Ecosistema Kafka (Tarea 2)**:
> - Zookeeper: Coordinaci√≥n de Kafka
> - Kafka Broker: Bus de mensajes central
> - Kafka Init: Creaci√≥n autom√°tica de 7 t√≥picos
> 
> **Servicios de Aplicaci√≥n**:
> - Storage Service: Persistencia as√≠ncrona
> - LLM Consumer (x2 r√©plicas): Procesamiento de preguntas
> - Retry Overload Consumer: Reintentos por sobrecarga
> - Retry Quota Consumer: Reintentos por l√≠mite de cuota
> - Score Validator: C√°lculo de BERTScore
> 
> **Apache Flink**:
> - Flink JobManager: Coordinador
> - Flink TaskManager: Ejecutor
> 
> **Monitoreo**:
> - Kafka UI: Visualizaci√≥n de t√≥picos y mensajes
> - Viz Service: Dashboard de m√©tricas y scores
> - Traffic Generator: Simulador de carga"

### 2.2 Mostrar Topolog√≠a de T√≥picos de Kafka

```powershell
Write-Host "`n=== TOPOLOG√çA DE KAFKA ===" -ForegroundColor Yellow
Write-Host @"

T√ìPICOS DISE√ëADOS (7 en total):

1. questions-pending
   Prop√≥sito: Preguntas nuevas que requieren procesamiento
   Productores: Storage Service, Flink (feedback loop)
   Consumidores: LLM Consumer (2 r√©plicas)
   Particiones: 3 (paralelismo)

2. llm-responses-success
   Prop√≥sito: Respuestas exitosas del LLM
   Productores: LLM Consumer
   Consumidores: Flink Job (ScoreValidator)
   Particiones: 3

3. llm-responses-error-overload
   Prop√≥sito: Errores por sobrecarga del modelo
   Productores: LLM Consumer
   Consumidores: Retry Overload Consumer
   Particiones: 2
   Estrategia: Exponential backoff (2, 4, 8 segundos)

4. llm-responses-error-quota
   Prop√≥sito: Errores por l√≠mite de cuota
   Productores: LLM Consumer
   Consumidores: Retry Quota Consumer
   Particiones: 2
   Estrategia: Delay fijo 60 segundos

5. validated-responses
   Prop√≥sito: Respuestas validadas por Flink (score ‚â• umbral)
   Productores: Flink Job
   Consumidores: Storage Service
   Particiones: 3

6. low-quality-responses
   Prop√≥sito: Respuestas bajo umbral (m√©tricas)
   Productores: Flink Job
   Consumidores: Ninguno (solo logging)
   Particiones: 1

7. llm-responses-error-permanent
   Prop√≥sito: Errores tras m√°ximo de reintentos
   Productores: Retry Consumers
   Consumidores: Ninguno (registro permanente)
   Particiones: 1

"@
```

**Narraci√≥n**:
> "Dise√±amos una topolog√≠a de 7 t√≥picos que gestiona todo el ciclo de vida de una consulta, desde su ingreso hasta su persistencia o descarte. Cada t√≥pico tiene un prop√≥sito espec√≠fico y est√° dimensionado seg√∫n su carga esperada."

---

## 3. PIPELINE AS√çNCRONO CON KAFKA

### 3.1 Iniciar el Sistema Completo

```powershell
Write-Host "`n=== INICIANDO SISTEMA ===" -ForegroundColor Green
docker-compose -f docker-compose-tarea2.yml up -d

# Esperar a que los servicios est√©n listos
Write-Host "`nEsperando a que los servicios inicien..." -ForegroundColor Yellow
Start-Sleep -Seconds 30

# Verificar estado
docker ps --format "table {{.Names}}\t{{.Status}}" | Select-String -Pattern "NAME|postgres|redis|kafka|flink|zookeeper|llm|storage|score|retry|viz"
```

**Narraci√≥n**:
> "Iniciamos los 15 contenedores de forma orquestada. Docker Compose maneja las dependencias autom√°ticamente: primero inicia PostgreSQL y Zookeeper, luego Kafka, despu√©s los servicios de aplicaci√≥n, y finalmente Flink."

### 3.2 Verificar T√≥picos de Kafka

```powershell
Write-Host "`n=== VERIFICANDO T√ìPICOS DE KAFKA ===" -ForegroundColor Cyan
docker exec kafka_broker kafka-topics --bootstrap-server localhost:9092 --list
```

**Narraci√≥n**:
> "Los 7 t√≥picos se crearon autom√°ticamente al iniciar el sistema. Veamos sus configuraciones detalladas..."

```powershell
# Ver detalles de un t√≥pico clave
docker exec kafka_broker kafka-topics --bootstrap-server localhost:9092 --describe --topic questions-pending
```

**Narraci√≥n**:
> "El t√≥pico 'questions-pending' tiene 3 particiones para distribuir la carga entre los 2 consumidores LLM, proporcionando paralelismo y tolerancia a fallos."

### 3.3 Abrir Kafka UI

```powershell
Write-Host "`n=== ABRIENDO KAFKA UI ===" -ForegroundColor Yellow
Start-Process "http://localhost:8080"
```

**Narraci√≥n**:
> "Kafka UI nos permite visualizar en tiempo real:
> - Los 7 t√≥picos configurados
> - Mensajes en cada t√≥pico
> - Grupos de consumidores activos
> - Lag de procesamiento
> - Throughput del sistema"

---

## 4. GESTI√ìN DE FALLOS Y REINTENTOS

### 4.1 Verificar Base de Datos Inicial

```powershell
Write-Host "`n=== ESTADO INICIAL DE LA BASE DE DATOS ===" -ForegroundColor Cyan
docker exec postgres_db psql -U user -d yahoo_db -c "SELECT COUNT(*) as total_respuestas FROM responses;"
```

**Narraci√≥n**:
> "Actualmente tenemos 7,887 respuestas en la base de datos, todas procesadas por Flink con el umbral anterior de 0.75. Vamos a demostrar el sistema con nuevas consultas."

### 4.2 Generar Tr√°fico de Prueba

```powershell
Write-Host "`n=== GENERANDO TR√ÅFICO DE PRUEBA ===" -ForegroundColor Green

# Ejecutar generador con 50 preguntas
docker exec traffic_generator python generate_traffic.py --num-requests 50 --interval 500
```

**Narraci√≥n**:
> "El generador de tr√°fico env√≠a 50 preguntas al sistema a un ritmo de 500ms por consulta. Cada pregunta sigue este flujo:
> 
> 1. **Storage Service consulta PostgreSQL**
>    - Si existe ‚Üí devuelve respuesta cacheada
>    - Si no existe ‚Üí publica en 'questions-pending'
> 
> 2. **LLM Consumer procesa la pregunta**
>    - √âxito ‚Üí publica en 'llm-responses-success'
>    - Error de sobrecarga ‚Üí publica en 'llm-responses-error-overload'
>    - Error de cuota ‚Üí publica en 'llm-responses-error-quota'
> 
> 3. **Consumidores de Reintento manejan errores**
>    - Overload: Exponential backoff (2s, 4s, 8s)
>    - Quota: Delay fijo de 60s
>    - M√°ximo 3 intentos por pregunta"

### 4.3 Monitorear Procesamiento en Tiempo Real

```powershell
Write-Host "`n=== MONITOREANDO LOGS DE CONSUMIDORES ===" -ForegroundColor Yellow

# Ver logs de LLM Consumer
docker logs llm-consumer-1 --tail 20 --follow
```

**Narraci√≥n** (mientras se ven los logs):
> "Observamos el procesamiento en tiempo real:
> - ‚úÖ Preguntas procesadas exitosamente
> - ‚ö†Ô∏è Errores capturados y encolados para reintento
> - üîÑ Reintentos autom√°ticos con backoff
> - üìä M√©tricas de rendimiento"

```powershell
# Ver logs del Retry Overload Consumer
docker logs retry_overload_consumer --tail 20
```

**Narraci√≥n**:
> "El consumidor de reintentos por sobrecarga implementa exponential backoff:
> - Intento 1: Espera 2 segundos
> - Intento 2: Espera 4 segundos
> - Intento 3: Espera 8 segundos
> 
> Esto previene saturar el LLM cuando est√° sobrecargado."

### 4.4 Verificar M√©tricas en Kafka UI

**Narraci√≥n** (en la interfaz de Kafka UI):
> "En Kafka UI podemos ver:
> 
> **T√≥pico 'questions-pending'**:
> - Mensajes producidos: ~50
> - Mensajes consumidos: ~50
> - Lag: 0 (procesamiento al d√≠a)
> 
> **T√≥pico 'llm-responses-success'**:
> - Respuestas exitosas acumul√°ndose
> - Esperando procesamiento de Flink
> 
> **T√≥picos de Error**:
> - 'llm-responses-error-overload': X mensajes
> - 'llm-responses-error-quota': Y mensajes
> - Ambos siendo reprocesados autom√°ticamente"

---

## 5. PROCESAMIENTO DE FLUJOS CON FLINK

### 5.1 Desplegar Job de Flink

```powershell
Write-Host "`n=== DESPLEGANDO JOB DE FLINK ===" -ForegroundColor Cyan

# Copiar JAR al contenedor (si no est√° montado como volumen)
docker cp "flink-job\target\flink-score-validator-1.0.jar" flink_jobmanager:/opt/flink/

# Desplegar en modo detached (-d)
docker exec flink_jobmanager flink run -d /opt/flink/flink-score-validator-1.0.jar
```

**Narraci√≥n**:
> "Desplegamos el job de Flink en modo detached (-d) para que se ejecute en segundo plano. El job procesar√° continuamente los mensajes del t√≥pico 'llm-responses-success'."

### 5.2 Abrir Flink UI

```powershell
Write-Host "`n=== ABRIENDO FLINK UI ===" -ForegroundColor Yellow
Start-Process "http://localhost:8081"
```

**Narraci√≥n**:
> "La interfaz de Flink muestra el job 'Score Validator' corriendo activamente con el nuevo umbral de 0.85."

### 5.3 Verificar Estado del Job

```powershell
Write-Host "`n=== VERIFICANDO JOB DE FLINK ===" -ForegroundColor Cyan
docker exec flink_jobmanager flink list
```

**Narraci√≥n**:
> "Nuestro job de Flink est√° en estado RUNNING con JobID visible. Este job:
> 
> 1. **Consume** del t√≥pico 'llm-responses-success'
> 2. **Calcula BERTScore** llamando al servicio score_validator
> 3. **Decide** bas√°ndose en el umbral de calidad (0.85):
>    - Score ‚â• 0.85 ‚Üí Publica en 'validated-responses'
>    - Score < 0.85 ‚Üí Reinyecta en 'questions-pending'
> 4. **Previene ciclos infinitos** limitando a 3 reintentos"

### 5.4 Mostrar el C√≥digo del Job de Flink

```powershell
Write-Host "`n=== C√ìDIGO DEL JOB DE FLINK ===" -ForegroundColor Cyan
Get-Content "flink-job\src\main\java\com\yahoo\flink\ScoreValidatorJob.java" | Select-Object -First 50
```

**Narraci√≥n**:
> "El c√≥digo muestra:
> - QUALITY_THRESHOLD = 0.85 (justificado por an√°lisis estad√≠stico)
> - MAX_RETRIES = 3 (previene ciclos infinitos)
> - L√≥gica de filtrado y enrutamiento de streams
> - Integraci√≥n con score_validator v√≠a HTTP"

### 5.5 Ver M√©tricas de Flink en Tiempo Real

**Narraci√≥n** (en Flink UI):
> "En la interfaz podemos observar:
> 
> **Task Metrics**:
> - Records In: Respuestas procesadas
> - Records Out: Decisiones tomadas
> - Latency: Tiempo de procesamiento por mensaje
> 
> **Operators**:
> - Kafka Source: Consumiendo 'llm-responses-success'
> - Score Calculator: Calculando BERTScore
> - Decision Splitter: Enrutando seg√∫n umbral
> - Kafka Sinks: Publicando a destinos apropiados
> 
> **Checkpointing**:
> - Estado persistente cada 30 segundos
> - Tolerancia a fallos garantizada"

### 5.5 Justificaci√≥n del Umbral de Calidad

```powershell
Write-Host "`n=== AN√ÅLISIS DE UMBRAL DE CALIDAD ===" -ForegroundColor Yellow
Get-Content "ANALISIS_SCORES.md" | Select-Object -First 100
```

**Narraci√≥n**:
> "Tras analizar 7,887 respuestas iniciales, determinamos:
> 
> **Estad√≠sticas de la Distribuci√≥n**:
> - Promedio: 0.851
> - Mediana: 0.850
> - Desviaci√≥n Est√°ndar: 0.058
> - Rango: 0.750 - 0.950
> 
> **Justificaci√≥n del Umbral 0.85**:
> 1. Corresponde a la mediana de la distribuci√≥n
> 2. Balance √≥ptimo: 50% pasan, 50% se regeneran
> 3. Costo computacional razonable
> 4. Mejora tangible en la calidad final
> 
> **Alternativas Evaluadas**:
> - 0.75: Muy permisivo (100% pasan)
> - 0.80: Moderado (78% pasan, 22% regeneran)
> - 0.85: **SELECCIONADO** (50% pasan, 50% regeneran)
> - 0.90: Muy estricto (25% pasan, 75% regeneran)"

---

## 6. AN√ÅLISIS DE M√âTRICAS

### 6.1 Abrir Dashboard de Visualizaci√≥n

```powershell
Write-Host "`n=== ABRIENDO DASHBOARD DE M√âTRICAS ===" -ForegroundColor Green
Start-Process "http://localhost:5002"
```

**Narraci√≥n**:
> "Nuestro dashboard muestra 5 gr√°ficos interactivos con datos en tiempo real, actualiz√°ndose cada 30 segundos."

### 6.2 Analizar Distribuci√≥n de Scores

**Narraci√≥n** (en el dashboard):
> "**Gr√°fico 1: Distribuci√≥n de Scores**
> 
> Observamos c√≥mo se distribuyen los scores de calidad:
> - 0.75-0.8: X% (Aceptable, pero en el l√≠mite)
> - 0.8-0.85: X% (Bueno, cerca del umbral)
> - 0.85-0.9: X% (Muy bueno, superan el umbral)
> - 0.9-1.0: X% (Excelente, m√°xima calidad)
> 
> Esto valida nuestra decisi√≥n de usar 0.85 como umbral."

### 6.3 Analizar Reintentos de Procesamiento

**Narraci√≥n** (en el dashboard):
> "**Gr√°fico 2: Intentos de Procesamiento**
> 
> Este gr√°fico tipo dona muestra:
> - X% con 1 intento (pasaron directo)
> - X% con 2 intentos (regeneradas 1 vez)
> - X% con 3 intentos (m√°ximo reintentos)
> 
> Esto demuestra que el feedback loop est√° funcionando activamente."

### 6.4 Verificar Mejora de Calidad

**Narraci√≥n** (en el dashboard):
> "**Gr√°fico 4: Mejora por Reintentos**
> 
> Este gr√°fico lineal demuestra la efectividad del ciclo de feedback:
> - Score promedio con 1 intento: X.XX
> - Score promedio con 2 intentos: X.XX (+X% mejora)
> - Score promedio con 3 intentos: X.XX (+X% mejora)
> 
> **Conclusi√≥n**: El feedback loop mejora la calidad en aproximadamente X% por reintento."

### 6.5 Consultar Estad√≠sticas Detalladas

```powershell
Write-Host "`n=== ESTAD√çSTICAS DEL SISTEMA ===" -ForegroundColor Cyan

# Total de respuestas procesadas
docker exec postgres_db psql -U user -d yahoo_db -c "
SELECT 
    COUNT(*) as total,
    ROUND(AVG(bert_score)::numeric, 3) as score_promedio,
    ROUND(STDDEV(bert_score)::numeric, 3) as desviacion,
    ROUND(MIN(bert_score)::numeric, 3) as min_score,
    ROUND(MAX(bert_score)::numeric, 3) as max_score
FROM responses;
"

# Distribuci√≥n por intentos
docker exec postgres_db psql -U user -d yahoo_db -c "
SELECT 
    processing_attempts as intentos,
    COUNT(*) as cantidad,
    ROUND(AVG(bert_score)::numeric, 3) as score_promedio,
    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM responses), 1) as porcentaje
FROM responses
GROUP BY processing_attempts
ORDER BY processing_attempts;
"
```

**Narraci√≥n**:
> "Las consultas SQL confirman los datos visualizados:
> - Total de respuestas procesadas
> - Score promedio general
> - Mejora incremental con cada reintento
> - Distribuci√≥n de reintentos"

### 6.6 Calcular Costo Computacional

```powershell
Write-Host "`n=== C√ÅLCULO DE COSTO COMPUTACIONAL ===" -ForegroundColor Yellow

docker exec postgres_db psql -U user -d yahoo_db -c "
SELECT 
    COUNT(*) as total_preguntas,
    SUM(processing_attempts) as total_llamadas_llm,
    ROUND(AVG(processing_attempts)::numeric, 2) as promedio_llamadas,
    ROUND((SUM(processing_attempts)::numeric - COUNT(*)) / COUNT(*) * 100, 1) as overhead_porcentaje
FROM responses;
"
```

**Narraci√≥n**:
> "El costo computacional del feedback loop:
> 
> - **Total de preguntas**: X
> - **Total de llamadas al LLM**: Y
> - **Overhead**: (Y-X)/X = Z%
> 
> Esto significa que el sistema realiza un Z% m√°s de llamadas al LLM para garantizar calidad. Este overhead es aceptable considerando la mejora de X% en el score promedio."

---

## 7. PREGUNTAS Y RESPUESTAS

### Q1: ¬øPor qu√© usar Apache Kafka en lugar de llamadas directas?

**Respuesta**:
```powershell
Write-Host @"
VENTAJAS DEL MODELO AS√çNCRONO:

1. DESACOPLAMIENTO:
   - Los servicios no dependen de la disponibilidad inmediata de otros
   - Tolerancia a fallos: si el LLM falla, las preguntas esperan en la cola
   - Escalabilidad independiente de cada componente

2. RESILIENCIA:
   - Persistencia de mensajes: no se pierde informaci√≥n en caso de fallo
   - Reintentos autom√°ticos sin afectar al cliente
   - Distribuci√≥n de carga entre m√∫ltiples consumidores

3. RENDIMIENTO:
   - Throughput: Procesamos ~X preguntas/segundo
   - Latencia as√≠ncrona: El usuario no espera el procesamiento completo
   - Buffer de carga: Kafka absorbe picos de tr√°fico

DESVENTAJAS:

1. COMPLEJIDAD:
   - M√°s componentes que mantener (Zookeeper, Kafka, consumidores)
   - Curva de aprendizaje para el equipo

2. LATENCIA PERCIBIDA:
   - Modelo s√≠ncrono: respuesta inmediata
   - Modelo as√≠ncrono: respuesta eventual (segundos a minutos)
   - Requiere sistema de notificaciones o polling

3. CONSISTENCIA:
   - Eventual consistency vs strong consistency
   - Requiere manejo cuidadoso del estado
"@
```

### Q2: ¬øC√≥mo se justifica la estrategia de reintento?

**Respuesta**:
```powershell
Write-Host @"
ESTRATEGIA DE REINTENTOS IMPLEMENTADA:

1. ERROR POR SOBRECARGA (Exponential Backoff):
   - Intento 1: 2 segundos
   - Intento 2: 4 segundos
   - Intento 3: 8 segundos
   
   JUSTIFICACI√ìN:
   - El modelo necesita tiempo para recuperarse
   - Evita saturar m√°s el sistema
   - Aumenta probabilidad de √©xito con cada intento

2. ERROR POR CUOTA (Fixed Delay):
   - Delay fijo: 60 segundos
   
   JUSTIFICACI√ìN:
   - Los l√≠mites de cuota se resetean cada minuto
   - No tiene sentido reintentar antes
   - Ahorra recursos del sistema

3. M√ÅXIMO DE REINTENTOS:
   - L√≠mite: 3 intentos
   
   JUSTIFICACI√ìN:
   - Previene ciclos infinitos
   - Balance entre calidad y costo
   - Errores permanentes van a t√≥pico dedicado

DATOS DE EFECTIVIDAD:
"@

docker exec postgres_db psql -U user -d yahoo_db -c "
SELECT 
    CASE 
        WHEN processing_attempts = 1 THEN '√âxito al primer intento'
        WHEN processing_attempts = 2 THEN 'Recuperadas tras 1 reintento'
        WHEN processing_attempts = 3 THEN 'Recuperadas tras 2 reintentos'
    END as categoria,
    COUNT(*) as cantidad,
    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM responses), 1) as porcentaje
FROM responses
GROUP BY processing_attempts
ORDER BY processing_attempts;
"
```

### Q3: ¬øC√≥mo se previenen ciclos infinitos en el feedback loop de Flink?

**Respuesta**:
```powershell
Write-Host @"
MECANISMOS DE PREVENCI√ìN DE CICLOS INFINITOS:

1. CONTADOR DE REINTENTOS:
   - Cada mensaje incluye campo 'processing_attempts'
   - Se incrementa en cada iteraci√≥n del loop
   - Verificado antes de reinyectar

2. L√çMITE M√ÅXIMO:
   - MAX_RETRIES = 3 en ScoreValidatorJob.java
   - Respuestas que alcanzan el l√≠mite:
     * Se marcan como 'max_retries_reached'
     * Se persisten con su mejor score obtenido
     * No se reinyectan m√°s

3. ENRUTAMIENTO INTELIGENTE:
   - Flink usa filtros de stream:
     * score < THRESHOLD && retries < MAX ‚Üí Regenerar
     * score >= THRESHOLD || retries >= MAX ‚Üí Persistir

4. MONITOREO:
   - Dashboard muestra distribuci√≥n de intentos
   - Alertas si todas las respuestas alcanzan m√°ximo

VERIFICACI√ìN:
"@

docker exec postgres_db psql -U user -d yahoo_db -c "
SELECT 
    MAX(processing_attempts) as max_intentos_observado,
    COUNT(CASE WHEN processing_attempts >= 3 THEN 1 END) as respuestas_limite_maximo
FROM responses;
"

Write-Host @"

CONCLUSI√ìN:
- Ninguna respuesta excede 3 intentos ‚úÖ
- El sistema respeta el l√≠mite configurado ‚úÖ
"@
```

### Q4: ¬øQu√© tecnolog√≠as alternativas se evaluaron?

**Respuesta**:
```powershell
Write-Host @"
COMPARACI√ìN DE TECNOLOG√çAS:

KAFKA vs RabbitMQ:
‚úÖ Kafka: Elegido por throughput superior y persistencia durable
‚ùå RabbitMQ: Mejor para enrutamiento complejo, pero menor throughput

FLINK vs Spark Streaming:
‚úÖ Flink: Latencia m√°s baja (milisegundos), streaming puro
‚ùå Spark: Micro-batching, latencia m√°s alta (segundos)

OLLAMA vs API de Gemini:
‚úÖ Ollama: Sin l√≠mites de rate, ejecuci√≥n local, control total
‚ùå Gemini: Requiere internet, l√≠mites de cuota, pero mayor calidad

POSTGRESQL vs MongoDB:
‚úÖ PostgreSQL: ACID garantizado, consultas SQL complejas
‚ùå MongoDB: Esquema flexible, pero menos consistencia

REDIS vs Memcached:
‚úÖ Redis: Estructuras de datos avanzadas, persistencia opcional
‚ùå Memcached: M√°s simple, solo key-value
"@
```

### Q5: ¬øC√≥mo escala el sistema?

**Respuesta**:
```powershell
Write-Host @"
ESTRATEGIAS DE ESCALABILIDAD:

1. ESCALADO HORIZONTAL DE CONSUMIDORES:
   - LLM Consumer: Ya tiene 2 r√©plicas
   - Comando para escalar:
     docker-compose -f docker-compose-tarea2.yml up -d --scale llm-consumer=5
   
   - Kafka distribuye autom√°ticamente entre r√©plicas
   - Cada r√©plica procesa una partici√≥n diferente

2. ESCALADO DE KAFKA:
   - Aumentar particiones de t√≥picos:
     docker exec kafka_broker kafka-topics --alter \\
       --topic questions-pending --partitions 10
   
   - Agregar m√°s brokers para replicaci√≥n

3. ESCALADO DE FLINK:
   - Aumentar TaskManagers en docker-compose:
     deploy:
       replicas: 3
   
   - Flink redistribuye el procesamiento autom√°ticamente

4. ESCALADO DE ALMACENAMIENTO:
   - PostgreSQL: Replicaci√≥n read-replica
   - Redis: Redis Cluster con sharding

DEMOSTRACI√ìN DE ESCALADO:
"@

# Escalar consumidores LLM a 4 r√©plicas
docker-compose -f docker-compose-tarea2.yml up -d --scale llm-consumer=4

Start-Sleep -Seconds 10

# Verificar r√©plicas
docker ps --filter "name=llm-consumer" --format "table {{.Names}}\t{{.Status}}"
```

---

## 8. CIERRE Y LIMPIEZA

### 8.1 Mostrar Documentaci√≥n Final

```powershell
Write-Host "`n=== DOCUMENTACI√ìN ENTREGABLE ===" -ForegroundColor Green
Get-ChildItem -Filter "*.md" | Format-Table Name, @{Name="Tama√±o (KB)"; Expression={[math]::Round($_.Length/1KB, 2)}}, LastWriteTime
```

**Narraci√≥n**:
> "Toda la documentaci√≥n t√©cnica est√° disponible:
> - Arquitectura detallada
> - Justificaci√≥n de decisiones
> - An√°lisis de m√©tricas
> - Gu√≠as de despliegue
> - C√≥digo fuente comentado"

### 8.2 Estad√≠sticas Finales

```powershell
Write-Host "`n=== RESUMEN FINAL DEL SISTEMA ===" -ForegroundColor Cyan

docker exec postgres_db psql -U user -d yahoo_db -c "
SELECT 
    'Total Preguntas' as metrica, 
    COUNT(*)::text as valor 
FROM responses
UNION ALL
SELECT 
    'Score Promedio', 
    ROUND(AVG(bert_score)::numeric, 3)::text 
FROM responses
UNION ALL
SELECT 
    'Mejora vs Umbral Inicial', 
    ROUND((AVG(bert_score) - 0.75) / 0.75 * 100, 1)::text || '%' 
FROM responses
UNION ALL
SELECT 
    'Overhead Computacional', 
    ROUND((SUM(processing_attempts)::numeric - COUNT(*)) / COUNT(*) * 100, 1)::text || '%'
FROM responses;
"
```

### 8.3 Detener el Sistema (Opcional)

```powershell
Write-Host "`n=== DETENIENDO SISTEMA ===" -ForegroundColor Yellow
# docker-compose -f docker-compose-tarea2.yml down

Write-Host @"

‚úÖ DEMOSTRACI√ìN COMPLETADA

El sistema cumple con TODOS los requerimientos de la Tarea 2:
‚úÖ Pipeline as√≠ncrono con Kafka (7 t√≥picos dise√±ados)
‚úÖ Gesti√≥n de fallos con 2 estrategias de reintento
‚úÖ Procesamiento de flujos con Apache Flink
‚úÖ Feedback loop con prevenci√≥n de ciclos infinitos
‚úÖ Despliegue completo con Docker Compose
‚úÖ Documentaci√≥n t√©cnica exhaustiva
‚úÖ Dashboard de visualizaci√≥n de m√©tricas
‚úÖ An√°lisis justificado del umbral de calidad

Gracias por su atenci√≥n.
"@
```

---

## üìé ANEXOS

### A. Comandos √ötiles para Debugging

```powershell
# Ver logs de todos los servicios
docker-compose -f docker-compose-tarea2.yml logs --tail=50

# Ver logs de un servicio espec√≠fico
docker logs <container_name> --tail 100 --follow

# Ejecutar comando dentro de un contenedor
docker exec -it <container_name> bash

# Ver uso de recursos
docker stats

# Reiniciar un servicio espec√≠fico
docker-compose -f docker-compose-tarea2.yml restart <service_name>
```

### B. URLs de Interfaces

```
- Flink UI:      http://localhost:8081
- Kafka UI:      http://localhost:8080
- Dashboard:     http://localhost:5002
- Storage API:   http://localhost:5001
```

### C. Estructura de Archivos Clave

```
yahoo_llm_project/
‚îú‚îÄ‚îÄ docker-compose-tarea2.yml      # Orquestaci√≥n completa
‚îú‚îÄ‚îÄ flink-job/                     # Job compilado de Flink
‚îÇ   ‚îî‚îÄ‚îÄ target/
‚îÇ       ‚îî‚îÄ‚îÄ flink-score-validator-1.0.jar
‚îú‚îÄ‚îÄ llm_consumer/                  # Consumidor LLM as√≠ncrono
‚îú‚îÄ‚îÄ retry_consumers/               # Consumidores de reintento
‚îú‚îÄ‚îÄ score_validator/               # Servicio de c√°lculo de score
‚îú‚îÄ‚îÄ storage_service/               # Persistencia as√≠ncrona
‚îú‚îÄ‚îÄ viz_service/                   # Dashboard de m√©tricas
‚îú‚îÄ‚îÄ README_TAREA2_FLINK.md        # Arquitectura t√©cnica
‚îú‚îÄ‚îÄ CUMPLIMIENTO_TAREA2.md        # Verificaci√≥n de requerimientos
‚îú‚îÄ‚îÄ ANALISIS_SCORES.md            # Justificaci√≥n de umbral
‚îî‚îÄ‚îÄ GUION_DEMOSTRACION_TAREA2.md  # Este documento
```

---

**Tiempo estimado de demostraci√≥n**: 20-25 minutos  
**Requisitos previos**: Docker, Docker Compose, Ollama instalados  
**Hardware m√≠nimo**: 8GB RAM, 4 CPU cores, 20GB disco

---

*Documento creado para la demostraci√≥n de la Tarea 2*  
*Sistemas Distribuidos - 2025*
