# Sistema Yahoo LLM - Tarea 2 con Apache Flink

## ğŸ¯ DescripciÃ³n

Sistema completo de procesamiento asÃ­ncrono de consultas LLM con Apache Kafka y **Apache Flink**, implementando pipeline resiliente con reintentos, validaciÃ³n de calidad mediante BERTScore, y regeneraciÃ³n automÃ¡tica de respuestas de baja calidad.

## ğŸ—ï¸ Arquitectura Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Storage API    â”‚ â† HTTP POST /query
â”‚  (Flask:5001)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Produce
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APACHE KAFKA                          â”‚
â”‚  Topics: questions-pending, llm-requests, errors-*,     â”‚
â”‚          llm-responses-success, validated-responses     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚          â”‚                               â”‚
     â†“          â†“                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM      â”‚ â”‚ Retry        â”‚         â”‚ FLINK CLUSTER    â”‚
â”‚ Consumer â”‚ â”‚ Consumers    â”‚         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ (x2)     â”‚ â”‚ - Overload   â”‚         â”‚ â”‚ JobManager   â”‚ â”‚
â”‚          â”‚ â”‚ - Quota      â”‚         â”‚ â”‚   :8081      â”‚ â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
     â”‚              â”‚                  â”‚        â”‚         â”‚
     â”‚ Success      â”‚ Retry            â”‚ â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
     â†“              â†“                  â”‚ â”‚ TaskManager  â”‚ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  llm-responses-success      â”‚       â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ Score Validator  â”‚
           â”‚                          â”‚ Job (Java)       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚                  â”‚
                                      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚      â”‚
                          Score < 0.75 â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€ Score â‰¥ 0.75
                                  â”‚                         â”‚
                                  â†“                         â†“
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ questions-     â”‚       â”‚ validated-     â”‚
                         â”‚ pending        â”‚       â”‚ responses      â”‚
                         â”‚ (regenerar)    â”‚       â”‚ (persistir)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â”‚
                                                            â†“
                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                   â”‚  PostgreSQL    â”‚
                                                   â”‚  + Redis Cache â”‚
                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Servicios (14 contenedores)

### Infraestructura Base (5)
1. **postgres_db** - PostgreSQL 13
2. **redis_cache** - Redis 7 con polÃ­tica LRU
3. **zookeeper** - CoordinaciÃ³n Kafka
4. **kafka_broker** - Broker Kafka
5. **kafka_init** - Inicializador de topics

### AplicaciÃ³n (6)
6. **storage-service** - API REST (Flask:5001)
7. **llm-consumer-1** - Consumidor LLM (Ollama)
8. **llm-consumer-2** - Consumidor LLM (Ollama)
9. **retry-overload-consumer** - Reintentos 503
10. **retry-quota-consumer** - Reintentos 429
11. **score-validator** - HTTP API + Kafka Consumer

### Apache Flink (2)
12. **flink-jobmanager** - Coordinador Flink (:8081)
13. **flink-taskmanager** - Ejecutor de jobs

### Monitoreo (1)
14. **kafka-ui** - Interfaz grÃ¡fica Kafka (:8080)

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos

- **Docker** y **Docker Compose**
- **Maven 3.6+** (para compilar Flink job)
- **Java 11+** (para Maven)
- **Ollama** corriendo localmente en puerto 11434 con modelo `tinyllama`

### OpciÃ³n 1: Script Automatizado (Recomendado)

```powershell
cd "d:\U\Sistemas Distribuidos\Docker\yahoo_llm_project"
.\start-system.ps1
```

Este script:
1. âœ… Compila el Flink job con Maven
2. âœ… Detiene contenedores existentes
3. âœ… Levanta todos los servicios
4. âœ… Espera healthchecks
5. âœ… Despliega el Flink job automÃ¡ticamente

**Tiempo estimado:** 3-4 minutos

### OpciÃ³n 2: Manual

```powershell
# 1. Compilar Flink job
cd flink-job
mvn clean package -DskipTests
cd ..

# 2. Levantar servicios
docker-compose -f docker-compose-tarea2.yml up -d --build

# 3. Esperar 30 segundos para healthchecks
Start-Sleep -Seconds 30

# 4. Iniciar servicios manualmente (si Zookeeper se demora)
docker start kafka_broker
Start-Sleep -Seconds 15
docker start kafka_init storage_service yahoo_llm_project-llm-consumer-1 yahoo_llm_project-llm-consumer-2 retry_overload_consumer retry_quota_consumer score_validator kafka_ui traffic_generator
Start-Sleep -Seconds 10
docker start flink_jobmanager flink_taskmanager
Start-Sleep -Seconds 15

# 5. Desplegar Flink job
cd flink-job
.\deploy-job.ps1
```

## ğŸ” VerificaciÃ³n del Sistema

### 1. Contenedores UP

```powershell
docker ps --format "table {{.Names}}\t{{.Status}}"
```

DeberÃ­as ver **14 contenedores** corriendo.

### 2. Storage API

```powershell
curl http://localhost:5001/metrics
```

Respuesta esperada:
```json
{
  "total_responses": 7887,
  "cache_hits": 0,
  "db_errors": 0
}
```

### 3. Flink Job Desplegado

Accede a http://localhost:8081

- Ve a **"Running Jobs"**
- DeberÃ­as ver: `Flink Score Validator Job`
- Estado: **RUNNING**

### 4. Kafka Topics

Accede a http://localhost:8080

Topics esperados:
- `questions-pending`
- `llm-requests`
- `llm-responses-success`
- `llm-responses-error`
- `errors-overload`
- `errors-quota`
- `validated-responses`
- `low-quality-responses`

### 5. Score Validator API

```powershell
curl http://localhost:8000/health
```

Respuesta:
```json
{
  "status": "healthy",
  "service": "score-validator"
}
```

## ğŸ® Uso del Sistema

### Enviar pregunta

```powershell
curl -X POST http://localhost:5001/query `
  -H "Content-Type: application/json" `
  -d '{
    "question_text": "Â¿CuÃ¡l es la capital de Chile?",
    "original_answer": "La capital de Chile es Santiago"
  }'
```

### Flujo completo:

1. **Storage API** recibe pregunta â†’ produce a `questions-pending`
2. **LLM Consumer** consume â†’ llama Ollama â†’ produce a `llm-responses-success` o `llm-responses-error`
3. **Flink Job** consume success â†’ calcula BERTScore
   - **Score â‰¥ 0.75**: Produce a `validated-responses` â†’ **se persiste**
   - **Score < 0.75**: Produce a `questions-pending` â†’ **se regenera** (max 3 intentos)
4. **Score Validator** (Python) consume `llm-responses-success` en paralelo (backup)
5. Si hay errores 503/429: **Retry Consumers** reintentan con backoff

## ğŸ“Š Monitoreo

### Flink Dashboard
```powershell
Start-Process "http://localhost:8081"
```

MÃ©tricas disponibles:
- Jobs corriendo
- Throughput (mensajes/segundo)
- Latencia de procesamiento
- Checkpoints
- Backpressure

### Kafka UI
```powershell
Start-Process "http://localhost:8080"
```

Visualiza:
- Mensajes en cada topic
- Consumer groups
- Lag de consumidores
- ConfiguraciÃ³n de topics

### Logs en tiempo real

```powershell
# Flink
docker logs -f flink_jobmanager
docker logs -f flink_taskmanager

# Score Validator
docker logs -f score_validator

# LLM Consumers
docker logs -f yahoo_llm_project-llm-consumer-1

# Storage
docker logs -f storage_service

# Retry Consumers
docker logs -f retry_overload_consumer
docker logs -f retry_quota_consumer
```

## ğŸ¯ Cumplimiento de Requerimientos

### âœ… Pipeline AsÃ­ncrono con Kafka
- 8 tÃ³picos diseÃ±ados para gestiÃ³n completa del ciclo de vida
- Productores: Storage API, LLM Consumer, Retry Consumers, Flink Job
- Consumidores: LLM Consumer (x2), Retry Consumers (x2), Flink Job, Score Validator

### âœ… GestiÃ³n de Fallos y Reintentos
- **Errores 503 (Overload)**: Exponential backoff (2^n * 5s)
- **Errores 429 (Quota)**: Fixed delay (60s)
- Consumidores dedicados por tipo de error
- Desacoplamiento total de la lÃ³gica de reintentos

### âœ… Procesamiento de Flujos con Flink
- **Job Java/Scala** en Flink 1.18
- Lee desde `llm-responses-success`
- Calcula BERTScore (vÃ­a HTTP API a score_validator)
- DecisiÃ³n basada en umbral (0.75)
- ReinyecciÃ³n a `questions-pending` si score < 0.75
- Mecanismo anti-ciclos: mÃ¡ximo 3 reintentos

### âœ… DistribuciÃ³n y Despliegue
- **100% contenerizado** con Docker
- OrquestaciÃ³n con `docker-compose.yml` Ãºnico
- Servicios escalables (LLM consumers con replicas: 2)
- Healthchecks configurados
- VolÃºmenes persistentes para datos

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### Cambiar umbral de calidad

**Flink Job** (`flink-job/src/main/java/.../ScoreValidatorJob.java`):
```java
private static final double QUALITY_THRESHOLD = 0.75;  // Cambiar aquÃ­
```

Recompilar:
```powershell
cd flink-job
mvn clean package -DskipTests
docker exec flink_jobmanager flink cancel <job-id>
.\deploy-job.ps1
```

### Escalar LLM consumers

En `docker-compose-tarea2.yml`:
```yaml
llm-consumer:
  deploy:
    replicas: 4  # Aumentar de 2 a 4
```

### Cambiar estrategia de reintento

**Overload** (`retry_consumers/retry_overload_consumer.py`):
```python
delay = (2 ** retry_count) * 5  # Exponential backoff
```

**Quota** (`retry_consumers/retry_quota_consumer.py`):
```python
FIXED_DELAY_SECONDS = 60  # Cambiar delay
```

## ğŸ§ª Testing

### Test bÃ¡sico de flujo completo

```powershell
# 1. Enviar pregunta
$response = curl -X POST http://localhost:5001/query `
  -H "Content-Type: application/json" `
  -d '{"question_text":"Test?","original_answer":"Test answer"}' `
  | ConvertFrom-Json

$questionId = $response.question_id

# 2. Esperar procesamiento
Start-Sleep -Seconds 10

# 3. Verificar en Kafka UI
Start-Process "http://localhost:8080/ui/clusters/local/all-topics/validated-responses"

# 4. Ver logs de Flink
docker logs flink_jobmanager | Select-String "FLINK: Validando"
```

### Test de regeneraciÃ³n (score bajo)

```powershell
# Enviar pregunta con respuesta muy diferente a la original
curl -X POST http://localhost:5001/query `
  -H "Content-Type: application/json" `
  -d '{
    "question_text": "Â¿CuÃ¡l es la capital de Francia?",
    "original_answer": "La capital de Francia es ParÃ­s"
  }'

# Observar logs de Flink
docker logs -f flink_jobmanager | Select-String "Regenerando pregunta"
```

## ğŸ“ Estructura del Proyecto

```
Docker/yahoo_llm_project/
â”œâ”€â”€ docker-compose-tarea2.yml       # OrquestaciÃ³n (14 servicios)
â”œâ”€â”€ start-system.ps1                # Script de inicio automÃ¡tico
â”œâ”€â”€ flink-job/                      # Apache Flink Job
â”‚   â”œâ”€â”€ pom.xml                     # Maven config
â”‚   â”œâ”€â”€ Dockerfile                  # Build multi-stage
â”‚   â”œâ”€â”€ deploy-job.ps1              # Deploy script
â”‚   â”œâ”€â”€ README.md                   # Docs del job
â”‚   â””â”€â”€ src/main/java/.../          # CÃ³digo Java
â”‚       â””â”€â”€ ScoreValidatorJob.java  # Job principal
â”œâ”€â”€ llm_consumer/                   # Consumidor LLM
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ retry_consumers/                # Consumidores de reintentos
â”‚   â”œâ”€â”€ Dockerfile.overload
â”‚   â”œâ”€â”€ Dockerfile.quota
â”‚   â”œâ”€â”€ retry_overload_consumer.py
â”‚   â”œâ”€â”€ retry_quota_consumer.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ score_validator/                # API + Consumer Python
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py                      # Flask API + Kafka consumer
â”‚   â””â”€â”€ requirements.txt            # Incluye flask
â”œâ”€â”€ storage_service/                # API REST principal
â”œâ”€â”€ traffic_generator/              # Generador de carga
â”œâ”€â”€ postgres/                       # Schemas SQL
â””â”€â”€ redis/                          # ConfiguraciÃ³n Redis
```

## ğŸ”§ Troubleshooting

### Problema: Flink job no se despliega

```powershell
# Verificar que JobManager estÃ© healthy
docker ps | Select-String flink

# Ver logs
docker logs flink_jobmanager

# Reintentar despliegue manual
cd flink-job
.\deploy-job.ps1
```

### Problema: Maven no compila

```powershell
# Verificar Java
java -version  # Debe ser 11+

# Limpiar cache Maven
cd flink-job
mvn clean
Remove-Item -Recurse -Force ~/.m2/repository/com/yahoo
mvn package -DskipTests
```

### Problema: Zookeeper timeout

Este es un problema conocido. SoluciÃ³n:

```powershell
# Esperar 30 segundos y luego iniciar manualmente
Start-Sleep -Seconds 30
docker start kafka_broker
# ... resto de servicios
```

### Problema: Score Validator no responde HTTP

```powershell
# Verificar puerto expuesto
docker ps | Select-String score_validator

# Ver logs
docker logs score_validator | Select-String "Iniciando HTTP"

# Test directo
curl http://localhost:8000/health
```

## ğŸ“š Referencias

- **Apache Flink:** https://flink.apache.org/
- **Flink Kafka Connector:** https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/datastream/kafka/
- **BERTScore:** https://github.com/Tiiiger/bert_score
- **Kafka:** https://kafka.apache.org/

## ğŸ“ Decisiones de DiseÃ±o

### Â¿Por quÃ© Flink + Score Validator?

- **Flink**: Procesamiento de streams en tiempo real, decisiones de regeneraciÃ³n
- **Score Validator**: API HTTP para cÃ¡lculos de BERTScore, backup Kafka consumer
- **Ambos trabajan en paralelo**: Redundancia y flexibilidad

### Â¿Por quÃ© HTTP API en score_validator?

- Flink necesita calcular BERTScore sin reimplementar en Java
- score_validator ya tiene el modelo cargado (PyTorch + Transformers)
- HTTP API permite reutilizaciÃ³n del cÃ³digo Python existente

### Â¿Por quÃ© 2 LLM consumers?

- Escalabilidad: Procesar mÃ¡s mensajes en paralelo
- Resiliencia: Si uno falla, el otro sigue funcionando
- Load balancing: Kafka distribuye mensajes automÃ¡ticamente

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Sistemas Distribuidos - 2025
